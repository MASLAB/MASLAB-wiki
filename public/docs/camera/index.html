<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Camera how-to# Now that your robot can move itself, it’s time to give it some vision to understand its surrounding!
Prerequisites# Computer with Python installed. Python is already installed by default on the Pi. Webcam (provided USB webcam or laptop’s built-in) The following tutorial can generally be followed on your laptop using either the provided USB webcam or built-in webcam. For consistency between what you see while running on your laptop and while running on the Pi, we would recommend using the provided webcam. Using the built-in webcam is fine for testing out small things only.
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://example.org/docs/camera/">
  <meta property="og:site_name" content="MASLAB wiki">
  <meta property="og:title" content="Camera">
  <meta property="og:description" content="Camera how-to# Now that your robot can move itself, it’s time to give it some vision to understand its surrounding!
Prerequisites# Computer with Python installed. Python is already installed by default on the Pi. Webcam (provided USB webcam or laptop’s built-in) The following tutorial can generally be followed on your laptop using either the provided USB webcam or built-in webcam. For consistency between what you see while running on your laptop and while running on the Pi, we would recommend using the provided webcam. Using the built-in webcam is fine for testing out small things only.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">


  <meta itemprop="name" content="Camera">
  <meta itemprop="description" content="Camera how-to# Now that your robot can move itself, it’s time to give it some vision to understand its surrounding!
Prerequisites# Computer with Python installed. Python is already installed by default on the Pi. Webcam (provided USB webcam or laptop’s built-in) The following tutorial can generally be followed on your laptop using either the provided USB webcam or built-in webcam. For consistency between what you see while running on your laptop and while running on the Pi, we would recommend using the provided webcam. Using the built-in webcam is fine for testing out small things only.">
  <meta itemprop="wordCount" content="1274">

<title>Camera | MASLAB wiki</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="https://example.org/docs/camera/">
<link rel="stylesheet" href="/book.min.cc2c524ed250aac81b23d1f4af87344917b325208841feca0968fe450f570575.css" integrity="sha256-zCxSTtJQqsgbI9H0r4c0SRezJSCIQf7KCWj&#43;RQ9XBXU=" crossorigin="anonymous">


  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.1e87a118efc07aece2fd56dc6a3496809e20203731d5f9587538c96c1016d1e0.js" integrity="sha256-HoehGO/Aeuzi/VbcajSWgJ4gIDcx1flYdTjJbBAW0eA=" crossorigin="anonymous"></script>



  
</head>
<body dir="ltr" class="book-kind-page book-type-docs">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    
<aside class="book-menu">
  <div class="book-menu-content">
    
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>MASLAB wiki</span>
  </a>
</h2>


<div class="book-search hidden">
  <input id="book-search-input" type="text" 
    placeholder="Search"
    aria-label="Search"
    maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>













  
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/introduction/" class="">
      Introduction</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/electrical/" class="">
      Electrical</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/raspberry-pi/" class="">
      Raspberry Pi</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/ssh/" class="">
      SSH</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/shell/" class="">
      Using a Shell</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/git/" class="">
      Git</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/battery/" class="">
      Battery</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/camera/" class="active">
      Camera</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/software/" class="">
      Software</a>
  

        </li>
      
    
  </ul>













</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>



  </div>
</aside>
 

    <div class="book-page">
      <header class="book-header hidden">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/icons/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Camera</h3>

  <label for="toc-control">
    
    <img src="/icons/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#prerequisites">Prerequisites</a></li>
    <li><a href="#opencv">OpenCV</a>
      <ul>
        <li><a href="#opencv-for-python-installation">OpenCV for Python installation</a></li>
        <li><a href="#opencv-import">OpenCV import</a></li>
      </ul>
    </li>
    <li><a href="#basic-camera-usage">Basic camera usage</a>
      <ul>
        <li><a href="#read-camera-frame">Read camera frame</a></li>
        <li><a href="#write-camera-frame">Write camera frame</a></li>
        <li><a href="#view-camera-in-real-time">View camera in real-time</a></li>
      </ul>
    </li>
    <li><a href="#basic-images-processing">Basic /images processing</a>
      <ul>
        <li><a href="#color-space">Color space</a></li>
        <li><a href="#basic-examples">Basic examples</a></li>
      </ul>
    </li>
    <li><a href="#advanced-camera-usage">Advanced camera usage</a>
      <ul>
        <li><a href="#manual-settings">Manual settings</a></li>
        <li><a href="#calibration">Calibration</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="camera-how-to">Camera how-to<a class="anchor" href="#camera-how-to">#</a></h1>
<p>Now that your robot can move itself, it&rsquo;s time to give it some vision to understand its surrounding!</p>
<h2 id="prerequisites">Prerequisites<a class="anchor" href="#prerequisites">#</a></h2>
<ol>
<li>Computer with <a href="https://www.python.org/downloads/">Python installed</a>. Python is already installed by default on the Pi.</li>
<li>Webcam (provided USB webcam or laptop&rsquo;s built-in)</li>
</ol>
<blockquote class='book-hint tip'>
<p>The following tutorial can generally be followed on your laptop using either the provided USB webcam or built-in webcam. For consistency between what you see while running on your laptop and while running on the Pi, we would recommend using the provided webcam. Using the built-in webcam is fine for testing out small things only.</p></blockquote><h2 id="opencv">OpenCV<a class="anchor" href="#opencv">#</a></h2>
<p><a href="https://opencv.org/">OpenCV</a> (Open Computer Vision) has been the de-facto software library for doing /images processing (at least at MASLAB).</p>
<h3 id="opencv-for-python-installation">OpenCV for Python installation<a class="anchor" href="#opencv-for-python-installation">#</a></h3>
<h4 id="on-the-pi">On the Pi<a class="anchor" href="#on-the-pi">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>sudo apt install -y python3-opencv</span></span></code></pre></div><h4 id="on-your-computer">On your computer<a class="anchor" href="#on-your-computer">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>pip install opencv-python</span></span></code></pre></div><h3 id="opencv-import">OpenCV import<a class="anchor" href="#opencv-import">#</a></h3>
<p>To add OpenCV to your Python script, import it with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> cv2 <span style="color:#75715e"># OpenCV version 2</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np <span style="color:#75715e"># Numpy numerical library for mathematical operation on /images data</span></span></span></code></pre></div><h2 id="basic-camera-usage">Basic camera usage<a class="anchor" href="#basic-camera-usage">#</a></h2>
<p>With OpenCV <a href="#opencv">installed and imported</a>, you can let OpenCV capture what your camera see with <code>cv2.VideoCapture()</code>. In general, if the computer only has 1 camera installed, you can create a video capture device with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cap <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>VideoCapture(<span style="color:#ae81ff">0</span>) <span style="color:#75715e"># Capture from first camera</span></span></span></code></pre></div><p>In this code, the <code>0</code> indicates the camera index. For a simple single camera system, this is just the first camera that the system recognizes. If you are running this on your laptop, this means the built-in webcam (if any). If you attach the USB camera to the Pi and run on the Pi, it <em>should</em> be the USB camera.</p>
<p>If you are using the USB camera and want to try on your laptop and not the Pi, you may have to add additional arguments.</p>
<p>For Windows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cap <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>VideoCapture(<span style="color:#ae81ff">1</span>, cv2<span style="color:#f92672">.</span>CAP_DSHOW)</span></span></code></pre></div><p>For Linux:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cap <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>VideoCapture(<span style="color:#ae81ff">1</span>, cv2<span style="color:#f92672">.</span>CAP_V4L2)</span></span></code></pre></div><p>For Mac:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cap <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>VideoCapture(<span style="color:#ae81ff">1</span>, cv2<span style="color:#f92672">.</span>CAP_AVFoundation)</span></span></code></pre></div><p>With these, the <code>cv2.CAP_xxx</code> indicates the API needed to access the USB camera. This is different with different operating system. <code>1</code> indicates the next camera besides the built-in camera.</p>
<p>To get the exact API (backend) and the index, <code>cv2-enumerate-cameras</code> is a great tool: <a href="https://github.com/lukehugh/cv2_enumerate_cameras">https://github.com/lukehugh/cv2_enumerate_cameras</a></p>
<blockquote class='book-hint tip'>
<p>If you are running OpenCV on your laptop, you may need to allow Python to access the camera in your security settings and/or with your Antivirus software (if any).</p></blockquote><h3 id="read-camera-frame">Read camera frame<a class="anchor" href="#read-camera-frame">#</a></h3>
<p>To read a frame from the video capture device, we can use <code>cv2.read()</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>ret, frame <span style="color:#f92672">=</span> cap<span style="color:#f92672">.</span>read()</span></span></code></pre></div><p><code>cap.read()</code> returns 2 value, <code>ret</code> and <code>frame</code>. <code>ret</code> is a debugging value that will be <code>True</code> if a frame was captured successfully and <code>False</code> otherwise. If <code>ret == True</code>, <code>frame</code> is a valid OpenCV frame that can be processed.</p>
<h3 id="write-camera-frame">Write camera frame<a class="anchor" href="#write-camera-frame">#</a></h3>
<p>We can then save the frame with <code>cv2.imwrite</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cv2<span style="color:#f92672">.</span>imwrite(<span style="color:#e6db74">&#34;test_frame.png&#34;</span>, frame) <span style="color:#75715e"># Save frame to path &#34;test_frame.png&#34;</span></span></span></code></pre></div><p>With this code, <code>cv2.imwrite</code> will save the captured <code>frame</code> to an /images called <code>test_frame.png</code>. You can redirect it to another folder to keep things organized by creating a folder and change the path. i.e. <code>debug/test_frame.png</code>. Note that you will have to create the folder manually first. <code>imwrite</code> will <strong>silently</strong> not write to non-existent folder.</p>
<h3 id="view-camera-in-real-time">View camera in real-time<a class="anchor" href="#view-camera-in-real-time">#</a></h3>
<p>For more real-time debugging, you can run a loop with <code>cv2.imshow()</code> to continuously display the frame:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Adapted from https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Capture frame-by-frame</span>
</span></span><span style="display:flex;"><span>    ret, frame <span style="color:#f92672">=</span> cap<span style="color:#f92672">.</span>read()
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># if frame is read correctly ret is True</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> ret:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;Can&#39;t receive frame (stream end?). Exiting ...&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cv2<span style="color:#f92672">.</span>imshow(<span style="color:#e6db74">&#39;frame&#39;</span>, frame)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> cv2<span style="color:#f92672">.</span>waitKey(<span style="color:#ae81ff">1</span>) <span style="color:#f92672">==</span> ord(<span style="color:#e6db74">&#39;q&#39;</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">break</span></span></span></code></pre></div><p>With this code, an OpenCV window will pop up, showing the camera feed in real-time. <code>cv2.waitKey(1) == ord('q')</code> tells OpenCV to listen for <code>q</code> key press for <code>1</code> millisecond. So to quit the loop, press <code>q</code> on your keyboard. Closing the window will only make OpenCV pop another window up.</p>
<blockquote class='book-hint note'>
<p>For running <code>cv2.imshow</code> on the Pi, a graphical window is needed such that <a href="3-Raspberry-Pi#connecting-over-ssh">SSH</a> remote connection alone will not be able to display from the Pi. Therefore, you will need to test with <a href="3-Raspberry-Pi#connecting-over-rdp">RDP</a>.</p></blockquote><h2 id="basic-images-processing">Basic /images processing<a class="anchor" href="#basic-images-processing">#</a></h2>
<p>Now that you are able to get frames from the camera, you can do some basic /images processing.</p>
<h3 id="color-space">Color space<a class="anchor" href="#color-space">#</a></h3>
<p>With /images processing, it is important to understand how color is represented. By default, an OpenCV frame is encoded as an (height x width x 3) array. This array contains (height x width) pixels. Each pixel is encoded as an array of 3 values from 0 to 255 of [blue, red, green] channels (as opposed to the usual RGB). This is one <a href="https://www.geeksforgeeks.org/python/color-spaces-in-opencv-python/">color space</a> that OpenCV understands and easy for computer to understand. However, for object recognition based on color shades, it is difficult to compare.</p>
<p>For example, <code>bgr(191, 112, 43)</code> to <code>bgr(89, 52, 20)</code> may come from the same object at different lighting angles yet have wildly different RGB values.</p>
<!-- raw HTML omitted -->
<p>A better color space to compare would be <a href="https://en.wikipedia.org/wiki/HSL_and_HSV">HSV</a>. HSV is based on human perception of color and encodes color in 3 values:</p>
<ul>
<li>H - Hue: color shade as represented in a circle (0-179)</li>
<li>S - Saturation: color vibrancy (0-255)</li>
<li>V - Value: color brightness (0-255)</li>
</ul>
<p>With HSV, the two previous colors become <code>hsv(150, 198, 191)</code> and <code>hsv(150, 198, 89)</code>. In this case, the colors only differ by the brightness value as expected.</p>
<p>To convert from one color-space to another, <code>cv2.cvtColor()</code> can be used:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>hsv_frame <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(frame, cv2<span style="color:#f92672">.</span>COLOR_BGR2HSV)</span></span></code></pre></div><p>With this, <code>cv2.cvtColor</code> will convert <code>frame</code> to <code>hsv_frame</code> from the default BGR to HSV color space as specified by <code>cv2.COLOR_BGR2HSV</code>.</p>
<blockquote class='book-hint note'>
<p><code>cv2.imwrite</code> and <code>cv2.imshow</code> expects BGR by default. Therefore, using it on an HSV frame may result in some very ~artistic~ images.</p></blockquote><h3 id="basic-examples">Basic examples<a class="anchor" href="#basic-examples">#</a></h3>
<p>Here are a few quick examples to get you started:</p>
<ol>
<li><a href="https://www.geeksforgeeks.org/python/getting-started-with-python-opencv/">Getting Started with Python OpenCV</a>. Fundamental /images operations. Feel free to save a frame from the camera to follow along.</li>
<li><a href="https://github.com/MASLAB/cv-samples/blob/master/color_segmentation.py">Color segmentation</a>. From MASLAB 2020 to detect the biggest continuous green object. You may need to adjust the HSV mask correspondingly.</li>
<li><a href="https://github.com/MASLAB/opencv-example/tree/master?tab=readme-ov-file">Object distance detection</a>. More advanced object distance detection from 2025, following the <a href="https://maslab.mit.edu/2025/files/lecture8-slides.pdf">lecture slide</a>.</li>
</ol>
<h2 id="advanced-camera-usage">Advanced camera usage<a class="anchor" href="#advanced-camera-usage">#</a></h2>
<h3 id="manual-settings">Manual settings<a class="anchor" href="#manual-settings">#</a></h3>
<p>Laptop webcams and USB webcams are designed for very general usage such that there may be automatic settings such as exposure and white balance. These may be nice to have for changing environments but may trigger randomly and mess up your /images and color calibration. Therefore, it may help to manually control these.</p>
<h4 id="manual-exposure">Manual exposure<a class="anchor" href="#manual-exposure">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cap<span style="color:#f92672">.</span>set(cv2<span style="color:#f92672">.</span>CAP_PROP_AUTO_EXPOSURE, <span style="color:#ae81ff">0.25</span>)  <span style="color:#75715e"># Set to manual exposure mode with 0.25 &#34;magic number&#34;</span>
</span></span><span style="display:flex;"><span>cap<span style="color:#f92672">.</span>set(cv2<span style="color:#f92672">.</span>CAP_PROP_EXPOSURE, <span style="color:#f92672">-</span><span style="color:#ae81ff">7</span>)  <span style="color:#75715e"># Set exposure time to 2^-7 = 1/128 second</span></span></span></code></pre></div><h4 id="manual-white-balance">Manual white balance<a class="anchor" href="#manual-white-balance">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cap<span style="color:#f92672">.</span>set(cv2<span style="color:#f92672">.</span>CAP_PROP_AUTO_WB, <span style="color:#ae81ff">0.0</span>) <span style="color:#75715e"># Disable auto white balance</span>
</span></span><span style="display:flex;"><span>cap<span style="color:#f92672">.</span>set(cv2<span style="color:#f92672">.</span>CAP_PROP_WB_TEMPERATURE, <span style="color:#ae81ff">4200</span>) <span style="color:#75715e"># Set white balance temperature to 4200K</span></span></span></code></pre></div><h4 id="other-props">Other props<a class="anchor" href="#other-props">#</a></h4>
<p>Along with exposure and white balance, there are other properties that you may want to explore. They can be found here: <a href="https://docs.opencv.org/4.x/d4/d15/group__videoio__flags__base.html#ggaeb8dd9c89c10a5c63c139bf7c4f5704da5c790a640b290f73fcd279e8bbaf0f13">https://docs.opencv.org/4.x/d4/d15/group__videoio__flags__base.html#ggaeb8dd9c89c10a5c63c139bf7c4f5704da5c790a640b290f73fcd279e8bbaf0f13</a></p>
<blockquote class='book-hint tip'>
<p>Unfortunately the official documentation is quite poor in describing the values so you may have to rely a lot on other online resources / forums / <a href="https://github.com/opencv/opencv/issues">OpenCV GitHub issues</a></p></blockquote><h3 id="calibration">Calibration<a class="anchor" href="#calibration">#</a></h3>
<p>Due to the camera lens, captured images may be distorted, making straight features curved and curved features straight. For example:</p>
<!-- raw HTML omitted -->
<p>This makes it difficult to accurately estimate the true object position as /images processing algorithms often assume the inputs are non-distorted images.</p>
<p>To correct the /images, a calibration procedure is necessary to find how distorted the camera is and calculate a set of correction values to be applied after. This procedure can be found along with more detailed explanation for camera distortion at <a href="https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html">https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html</a></p>
<h4 id="calibration-pattern">Calibration pattern<a class="anchor" href="#calibration-pattern">#</a></h4>
<p>You will need a calibration pattern of checkered squares. Here is an example one with 2 x 2 cm squares: <a href="file/calibration.pdf">calibration.pdf</a>. When printing, make sure to apply no scaling to get the correct square size. Once you have a pattern, make sure to tape it down on a surface as flat as possible.</p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">

<div>

</div>

<div>

</div>

</div>





  
  
  
  <div class="flex flex-wrap justify-between">
    <span>
    
      <a href="/docs/battery/" class="flex align-center">
        <img src="/icons/backward.svg" class="book-icon" alt="Backward" />
        <span>Battery</span>
      </a>
    
    </span>
    <span>
    
      <a href="/docs/software/" class="flex align-center">
        <span>Software</span>
        <img src="/icons/forward.svg" class="book-icon" alt="Forward" />
      </a>
    
    </span>
  </div>
  


 
        
  
  <div class="book-comments">

</div>
  
 
        
        
  
 
        
  
  
    <script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script>
  

      </footer>

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
  
  <aside class="book-toc">
    <div class="book-toc-content">
      
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#prerequisites">Prerequisites</a></li>
    <li><a href="#opencv">OpenCV</a>
      <ul>
        <li><a href="#opencv-for-python-installation">OpenCV for Python installation</a></li>
        <li><a href="#opencv-import">OpenCV import</a></li>
      </ul>
    </li>
    <li><a href="#basic-camera-usage">Basic camera usage</a>
      <ul>
        <li><a href="#read-camera-frame">Read camera frame</a></li>
        <li><a href="#write-camera-frame">Write camera frame</a></li>
        <li><a href="#view-camera-in-real-time">View camera in real-time</a></li>
      </ul>
    </li>
    <li><a href="#basic-images-processing">Basic /images processing</a>
      <ul>
        <li><a href="#color-space">Color space</a></li>
        <li><a href="#basic-examples">Basic examples</a></li>
      </ul>
    </li>
    <li><a href="#advanced-camera-usage">Advanced camera usage</a>
      <ul>
        <li><a href="#manual-settings">Manual settings</a></li>
        <li><a href="#calibration">Calibration</a></li>
      </ul>
    </li>
  </ul>
</nav>



    </div>
  </aside>
  
 
  </main>

  
</body>
</html>




















